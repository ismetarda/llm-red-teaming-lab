# LLM Red Teaming & Vulnerability Lab ğŸ›¡ï¸

Bu proje, Yerel LLM modellerine (Mistral, TinyLlama) yÃ¶nelik otomatik **Red Teaming** ve **Jailbreak** saldÄ±rÄ± senaryolarÄ±nÄ± test etmek iÃ§in oluÅŸturulmuÅŸ bir siber gÃ¼venlik laboratuvar Ã§alÄ±ÅŸmasÄ±dÄ±r.

## ğŸš€ Ã–zellikler
* **Giskard Framework:** Zafiyet taramasÄ± ve model analizi.
* **LangChain Entegrasyonu:** Uzak sunucudaki (Host PC) Ollama modelleriyle iletiÅŸim.
* **Otomatik Prompt Injection:** Modele yasaklÄ± sorular (Jailbreak) sorarak gÃ¼venlik filtrelerini test etme.

## âš ï¸ Yasal UyarÄ±
Bu proje tamamen eÄŸitim ve etik gÃ¼venlik testleri amacÄ±yla geliÅŸtirilmiÅŸtir.
